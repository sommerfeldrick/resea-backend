# ğŸ¤– Guia de ConfiguraÃ§Ã£o - Multi-AI Provider

Esse documento explica como configurar o novo sistema multi-provider de IA.

## ğŸ“Š Arquitetura

```
AIService (Interface Simples)
    â†“
AIStrategyRouter (SeleÃ§Ã£o Inteligente)
    â†“
ProviderFactory (CriaÃ§Ã£o de InstÃ¢ncias)
    â†“
Providers EspecÃ­ficos (ImplementaÃ§Ã£o)
    â”œâ”€â”€ GeminiProvider (Google Gemini 2.5)
    â”œâ”€â”€ GroqProvider (Groq - Llama 3)
    â”œâ”€â”€ OpenRouterProvider (OpenRouter)
    â””â”€â”€ OllamaProvider (Modelos Locais)
```

## ğŸ¯ Prioridade dos Providers

1. **Gemini** (Primeira opÃ§Ã£o)
   - Melhor qualidade
   - Quase grÃ¡tis (free tier generoso)
   - 250 requisiÃ§Ãµes/dia grÃ¡tis

2. **Groq** (Segunda opÃ§Ã£o)
   - Muito rÃ¡pido (276 tokens/seg)
   - GrÃ¡tis atÃ© 100k tokens/dia
   - Excelente para tarefas rÃ¡pidas

3. **OpenRouter** (Terceira opÃ§Ã£o)
   - Acesso a mÃºltiplos modelos
   - CrÃ©ditos iniciais grÃ¡tis (~$5-10)
   - Fallback com flexibilidade

4. **Ollama** (Ãšltima opÃ§Ã£o)
   - 100% local e offline
   - 100% grÃ¡tis
   - Para backup/dados sensÃ­veis

## ğŸ”§ ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente

### Google Gemini 2.5 Flash (RECOMENDADO)

```bash
# 1. Acesse https://makersuite.google.com/app/apikey
# 2. Clique em "Create API Key"
# 3. Copie a chave
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-2.0-flash-exp
```

**Rate Limits (Free Tier):**
- 250 requisiÃ§Ãµes/dia
- 1.000.000 tokens/dia entrada
- 30.000 tokens/minuto

### Groq (RECOMENDADO - RÃ¡pido)

```bash
# 1. Acesse https://console.groq.com/
# 2. FaÃ§a login (suporta GitHub)
# 3. VÃ¡ para API Keys
# 4. Copie a chave
GROQ_API_KEY=your_key_here
GROQ_MODEL=llama-3.1-70b-versatile
```

**Rate Limits (Free Tier):**
- 30 requisiÃ§Ãµes/minuto
- 100.000 tokens/dia
- 12.000 tokens/minuto

### OpenRouter (Complementar)

```bash
# 1. Acesse https://openrouter.ai/
# 2. FaÃ§a login
# 3. VÃ¡ para Settings â†’ API Keys
# 4. Copie a chave
OPENROUTER_API_KEY=your_key_here
OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct:free
```

**CrÃ©ditos:**
- $5-$10 iniciais (grÃ¡tis)
- Modelos free: Llama 3, Mixtral
- Modelos pagos: GPT-4o, Claude, Gemini

### Ollama (Local - Offline)

```bash
# 1. Baixe em https://ollama.ai/
# 2. Instale e abra
# 3. No terminal, rode: ollama pull llama2
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
```

**CaracterÃ­sticas:**
- Roda localmente
- Sem limite de chamadas
- Sem conexÃ£o necessÃ¡ria
- Mais lento (GPU recomendada)

## ğŸ“ Exemplo de Uso

### Simples (AutomÃ¡tico - Melhor Provider)

```typescript
import { generateText } from './services/ai/index.js';

const response = await generateText(
  'Escreva um resumo sobre IA',
  { temperature: 0.7, maxTokens: 500 }
);

console.log(response.text);       // ConteÃºdo gerado
console.log(response.provider);   // Qual IA foi usada
console.log(response.cost);       // Custo em USD
```

### Com OpÃ§Ãµes

```typescript
import { generateText } from './services/ai/index.js';

// ForÃ§ar provider especÃ­fico
const response = await generateText(
  'Escreva um resumo sobre IA',
  {
    provider: 'gemini',           // ForÃ§a Gemini
    systemPrompt: 'VocÃª Ã© um professor',
    temperature: 0.5,
    maxTokens: 2000
  }
);
```

### Stream (ImplementaÃ§Ã£o Futura)

```typescript
import { generateTextStream } from './services/ai/index.js';

for await (const chunk of generateTextStream(prompt)) {
  process.stdout.write(chunk);
}
```

## ğŸ©º Monitorar SaÃºde

### Health Check

```bash
GET /api/ai/health
```

Resposta:
```json
{
  "healthy": true,
  "providers": {
    "gemini": {
      "available": true,
      "usage": { "tokensUsedToday": 50000 },
      "config": { "rateLimits": {...} }
    },
    "groq": {
      "available": true,
      "usage": { "tokensUsedToday": 25000 }
    }
  },
  "stats": {...}
}
```

### Reset Stats

```bash
POST /api/ai/reset-stats
```

## ğŸ’° Estimativa de Custos

### CenÃ¡rio 1: Uso Leve (10 req/dia)
- **Gemini**: $0 (dentro free tier)
- **Groq**: $0 (dentro free tier)
- **Total/mÃªs**: $0

### CenÃ¡rio 2: Uso Moderado (100 req/dia)
- **Gemini**: $0 (250 req/dia grÃ¡tis)
- **Groq**: $0 (100k tokens/dia grÃ¡tis)
- **Total/mÃªs**: $0-5

### CenÃ¡rio 3: Uso Intenso (1000 req/dia)
- **Gemini**: $0 (atÃ© 250 req/dia, depois $0.15 input + $0.60 output)
- **Groq**: $0 (atÃ© 100k tokens/dia, depois $0.59 input + $0.79 output)
- **OpenRouter**: $5-20 (modelos livres + pagos)
- **Total/mÃªs**: $50-200

## ğŸ”„ Fluxo de Fallback

```
RequisiÃ§Ã£o de IA
    â†“
[1] Gemini disponÃ­vel? â†’ USE
    â†“ (indisponÃ­vel/limite)
[2] Groq disponÃ­vel? â†’ USE
    â†“ (indisponÃ­vel/limite)
[3] OpenRouter disponÃ­vel? â†’ USE
    â†“ (indisponÃ­vel/limite)
[4] Ollama disponÃ­vel? â†’ USE
    â†“ (indisponÃ­vel)
[!] ERRO - Todas falharam
```

## ğŸ“Š Estrutura de DiretÃ³rios

```
src/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ aiService.ts (Interface Principal)
â”‚   â”‚   â”œâ”€â”€ AIStrategyRouter.ts (SeleÃ§Ã£o)
â”‚   â”‚   â”œâ”€â”€ types.ts (Types/Interfaces)
â”‚   â”‚   â”œâ”€â”€ index.ts (Exports)
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ providers.config.ts (ConfiguraÃ§Ã£o)
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â”œâ”€â”€ BaseAIProvider.ts (AbstraÃ§Ã£o)
â”‚   â”‚       â”œâ”€â”€ GeminiProvider.ts
â”‚   â”‚       â”œâ”€â”€ GroqProvider.ts
â”‚   â”‚       â”œâ”€â”€ OpenRouterProvider.ts
â”‚   â”‚       â”œâ”€â”€ OllamaProvider.ts
â”‚   â”‚       â””â”€â”€ ProviderFactory.ts (Factory)
â”‚   â””â”€â”€ ...outros services
â””â”€â”€ routes/
    â”œâ”€â”€ ai.ts (Health checks)
    â””â”€â”€ ...outros routes
```

## ğŸš€ Deploy no Render

No `render.yaml`, adicione as variÃ¡veis de ambiente:

```yaml
env:
  - key: GEMINI_API_KEY
    value: your_key_here
  - key: GROQ_API_KEY
    value: your_key_here
  - key: OPENROUTER_API_KEY
    value: your_key_here
  - key: OLLAMA_ENABLED
    value: "false"  # Desabilitado em produÃ§Ã£o (sem local)
```

## ğŸ“š ReferÃªncias

- [Google Gemini API](https://ai.google.dev/)
- [Groq API](https://console.groq.com/)
- [OpenRouter](https://openrouter.ai/)
- [Ollama](https://ollama.ai/)

## â“ Troubleshooting

### "Nenhum provedor disponÃ­vel"

**Causa**: Nenhuma chave de API configurada

**SoluÃ§Ã£o**:
```bash
# Configure pelo menos uma:
GEMINI_API_KEY=key
# ou
GROQ_API_KEY=key
# ou
OLLAMA_ENABLED=true
```

### "Rate limit atingido"

**Causa**: Excedeu limite diÃ¡rio do provider

**SoluÃ§Ã£o**: Sistema tenta automaticamente o prÃ³ximo provider. Monitore com `/api/ai/health`

### Ollama nÃ£o conecta

**Causa**: Servidor Ollama nÃ£o estÃ¡ rodando

**SoluÃ§Ã£o**:
```bash
# Mac/Linux/Windows:
ollama serve

# Depois em outro terminal:
ollama pull llama2
```

---

**Ãšltima atualizaÃ§Ã£o**: 30/10/2025
**VersÃ£o**: 2.0.0
**Status**: âœ… ProduÃ§Ã£o
