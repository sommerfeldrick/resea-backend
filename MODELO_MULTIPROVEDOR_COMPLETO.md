# ðŸš€ Sistema Multi-Provedor com TODOS os Modelos Gratuitos

## ðŸ“‹ SumÃ¡rio

Sistema inteligente com **42+ modelos gratuitos** de 4 providers, com fallback automÃ¡tico baseado em capacidade do free tier.

**Nova Prioridade:**
1. **Ollama Cloud** - 1M tokens/dia (1Âº lugar)
2. **Groq** - 100k tokens/dia (2Âº lugar)
3. **OpenRouter** - CrÃ©ditos flexÃ­veis (3Âº lugar)
4. **Gemini** - 250 req/dia (4Âº lugar)

---

## ðŸŽ¯ Todos os Modelos por Provider

### 1ï¸âƒ£ OLLAMA CLOUD (1M tokens/dia - PRIORIDADE 1)

**Modelos disponÃ­veis:**

```
QUALIDADE:
  âœ… gpt-oss:120b-cloud        â†’ 120B (Melhor qualidade/preÃ§o)
  âœ… deepseek-v3.1:671b-cloud  â†’ 671B (Ultra-poderoso)
  âœ… qwen3-coder:480b-cloud    â†’ 480B (Especializado em cÃ³digo)

BALANCEADO:
  âœ… gpt-oss:120b-cloud        â†’ 120B
  âœ… glm-4.6:cloud             â†’ GLM 4.6 (RÃ¡pido e qualidade)
  âœ… kimi-k2:cloud             â†’ Kimi K2

RÃPIDO:
  âœ… glm-4.6:cloud             â†’ GLM 4.6
  âœ… minimax-m2:cloud          â†’ MiniMax M2 (Ultra-leve)
```

**Limites:**
- 1M tokens/dia âœ…
- 100% na nuvem (sem servidor local)
- Modelo default: `gpt-oss:120b-cloud`

---

### 2ï¸âƒ£ GROQ (100k tokens/dia, 30 req/min - PRIORIDADE 2)

**Modelos disponÃ­veis:**

```
QUALIDADE:
  âœ… llama-3.1-70b-versatile   â†’ 70B (Melhor qualidade)

BALANCEADO:
  âœ… mixtral-8x7b-32768        â†’ 56B equivalente (Contexto de 32k!)

RÃPIDO:
  âœ… llama-3.1-8b-instruct     â†’ 8B (Ultra-rÃ¡pido: 276 tokens/s)
```

**Limites:**
- 100k tokens/dia
- 30 requisiÃ§Ãµes/minuto
- Muito rÃ¡pido (ideal para respostas em tempo real)

---

### 3ï¸âƒ£ OPENROUTER - 13+ Modelos Gratuitos (PRIORIDADE 3)

#### ðŸ† QUALIDADE (Frontier models)

```
âœ… nousresearch/hermes-3-llama-3.1-405b:free
   â†’ 405B (Modelo frontier)

âœ… deepseek/deepseek-chat-v3.1:free
   â†’ Ultra-poderoso, raciocÃ­nio avanÃ§ado

âœ… meta-llama/llama-3.3-70b-instruct:free
   â†’ 70B alternativo

âœ… qwen/qwen-2.5-72b-instruct:free
   â†’ 72B (Muito bom para anÃ¡lise)
```

#### âš–ï¸ BALANCEADO (Reasoning + Multimodal)

```
âœ… deepseek/deepseek-r1:free
   â†’ Modelo de raciocÃ­nio (pensa antes de responder)

âœ… meta-llama/llama-4-maverick:free
   â†’ MULTIMODAL (aceita imagens!)

âœ… meta-llama/llama-3.3-70b-instruct:free
   â†’ 70B alternativo

âœ… qwen/qwen-2.5-72b-instruct:free
   â†’ 72B alternativo
```

#### âš¡ RÃPIDO (Lightweight + Coding)

```
âœ… meta-llama/llama-3.3-8b-instruct:free
   â†’ 8B rÃ¡pido

âœ… qwen/qwen3-coder:free
   â†’ Especializado em programaÃ§Ã£o

âœ… deepseek/deepseek-r1-0528-qwen3-8b:free
   â†’ 8B com raciocÃ­nio

âœ… qwen/qwen3-4b:free
   â†’ 4B ultra-leve

âœ… deepseek/deepseek-r1-0528:free
   â†’ DeepSeek R1 versÃ£o 0528

âœ… mistralai/mistral-small-3.2-24b-instruct:free
   â†’ 24B MULTIMODAL (aceita imagens!)
```

**Limites:**
- CrÃ©ditos iniciais ($5-10) para free tier
- Modelos com `:free` nunca cobram
- Fallback automÃ¡tico para modelos pagos se necessÃ¡rio

---

### 4ï¸âƒ£ GEMINI (1M tokens/dia, 250 req/dia - PRIORIDADE 4)

**Modelos disponÃ­veis (via OpenRouter):**

```
QUALIDADE:
  âœ… google/gemini-2.0-flash-exp:free
     â†’ Flash Experimental (Ãºltimas features)

BALANCEADO:
  âœ… google/gemini-2.0-flash-exp:free

RÃPIDO:
  âœ… google/gemini-2.0-flash-exp:free
     â†’ Flash Ã© rÃ¡pido por padrÃ£o
```

**Limites:**
- 1M tokens/dia âœ…
- 250 requisiÃ§Ãµes/dia âš ï¸ (restritivo)
- Apenas como fallback final

---

## ðŸ’» Como Usar

### InstalaÃ§Ã£o de Chaves (`.env.example`)

```bash
# Ollama Cloud (recomendado)
OLLAMA_API_KEY=sk-ollama_...
OLLAMA_BASE_URL=https://ollama.com

# Groq (backup rÃ¡pido)
GROQ_API_KEY=gsk-proj_...

# OpenRouter (flexibility)
OPENROUTER_API_KEY=sk-or_...

# Gemini (Ãºltimo recurso)
GEMINI_API_KEY=AIzaSyD...
```

### No Render (Deployment)

VÃ¡ para **Dashboard â†’ Services â†’ Environment â†’ Add Variable**:

```
OLLAMA_API_KEY=sk-ollama_[sua_chave]
GROQ_API_KEY=gsk-proj_[sua_chave]
OPENROUTER_API_KEY=sk-or_[sua_chave]
GEMINI_API_KEY=AIzaSyD[sua_chave]
OLLAMA_BASE_URL=https://ollama.com
```

### No CÃ³digo (TypeScript)

```typescript
import { generateText } from './services/ai';

// 1ï¸âƒ£ AUTOMÃTICO - Usa melhor modelo disponÃ­vel
const response = await generateText('Seu prompt aqui');
console.log(`Usado: ${response.provider}`);

// 2ï¸âƒ£ COM QUALIDADE - Seleciona modelo por tier
const response = await generateText(prompt, {
  quality: 'quality'  // 'quality' | 'balanced' | 'fast'
});

// 3ï¸âƒ£ FORÃ‡AR PROVIDER
const response = await generateText(prompt, {
  provider: 'groq'
});

// 4ï¸âƒ£ TUDO CUSTOMIZADO
const response = await generateText(prompt, {
  quality: 'balanced',
  provider: 'openrouter',
  temperature: 0.7,
  maxTokens: 2000
});

console.log({
  text: response.text,
  provider: response.provider,
  model: response.model,
  tokensUsed: response.tokensUsed,
  cost: response.cost
});
```

---

## ðŸ”„ Fluxo de Fallback AutomÃ¡tico

```
RequisiÃ§Ã£o recebida
    â†“
Tenta: Ollama Cloud (1M tokens/dia)
â”œâ”€ âœ… Sucesso? Retorna resultado
â”œâ”€ âŒ Limite atingido ou erro? â†’ PrÃ³ximo
    â†“
Tenta: Groq (100k tokens/dia + 30 req/min)
â”œâ”€ âœ… Sucesso? Retorna resultado
â”œâ”€ âŒ Limite atingido ou erro? â†’ PrÃ³ximo
    â†“
Tenta: OpenRouter (MÃºltiplos modelos)
â”œâ”€ âœ… Sucesso? Retorna resultado
â”œâ”€ âŒ Erro? â†’ PrÃ³ximo
    â†“
Tenta: Gemini (250 req/dia)
â”œâ”€ âœ… Sucesso? Retorna resultado
â”œâ”€ âŒ Todos falharam? Erro para usuÃ¡rio
```

---

## ðŸ“Š RotaÃ§Ã£o Inteligente de Modelos

Sistema **rastreia sucesso/falha** de cada modelo e rotaciona automaticamente:

```typescript
import { rotationStrategy } from './config/ModelSelection';

// Taxa de sucesso
const rate = rotationStrategy.getSuccessRate('llama-3.1-70b-versatile', 60);
console.log(`Groq sucesso nos Ãºltimos 60 min: ${rate * 100}%`);

// Contar falhas
const failures = rotationStrategy.getFailureCount('gpt-oss:120b-cloud', 60);
console.log(`Ollama falhas: ${failures}`);

// Obter histÃ³rico
const history = rotationStrategy.getHistory(100);
console.log(history);

// Resetar (execute via cron diariamente)
rotationStrategy.reset();
```

---

## ðŸ“ˆ Monitoramento e SaÃºde

### Verificar Status dos Providers

```typescript
import { AIStrategyRouter } from './services/ai/AIStrategyRouter';

const health = await AIStrategyRouter.getHealth();
console.log(health);

// SaÃ­da:
// {
//   ollama: { available: true, tokensUsed: 45000, ... },
//   groq: { available: true, successRate: '98.5%', ... },
//   openrouter: { available: true, ... },
//   gemini: { available: false, error: 'API key missing' }
// }
```

### Ver EstatÃ­sticas de Uso

```typescript
const stats = AIStrategyRouter.getStats();
console.log(stats);

// {
//   ollama: {
//     requestsToday: 125,
//     tokensUsedToday: 450000,
//     costToday: 0,
//     failureCount: 2
//   },
//   ...
// }
```

---

## ðŸŽ¯ Casos de Uso Recomendados

| Caso | Provider | Modelo | Qualidade |
|------|----------|--------|-----------|
| **Resumo acadÃªmico** | Ollama â†’ Groq | 120B ou Llama 70B | Quality |
| **CorreÃ§Ã£o rÃ¡pida** | Groq | Llama 8B | Fast |
| **AnÃ¡lise pesquisa** | Ollama | GPT-OSS 120B | Balanced |
| **Processamento imagem** | OpenRouter | Llama-4-Maverick | Balanced |
| **CÃ³digo especializado** | Groq | Mistral 8x7B | Balanced |
| **RaciocÃ­nio complexo** | OpenRouter | DeepSeek-R1 | Quality |
| **Fallback final** | Gemini | Gemini 2.0 Flash | Fast |

---

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### ModelSelection.ts (Arrays de modelos)

```typescript
// NOVO: Arrays com fallback automÃ¡tico
export const freeModels = {
  ollama: {
    quality: [
      'gpt-oss:120b-cloud',           // 1Âº preferido
      'deepseek-v3.1:671b-cloud',     // 2Âº fallback
      'qwen3-coder:480b-cloud'        // 3Âº fallback
    ],
    balanced: [
      'gpt-oss:120b-cloud',
      'glm-4.6:cloud',
      'kimi-k2:cloud'
    ],
    fast: [
      'glm-4.6:cloud',
      'minimax-m2:cloud',
      'gpt-oss:120b-cloud'
    ]
  },
  // ... outros providers
};
```

### providers.config.ts (Prioridade dos providers)

```typescript
// Ordem: Ollama â†’ Groq â†’ OpenRouter â†’ Gemini
export const fallbackOrder: AIProvider[] = [
  'ollama',       // 1M tokens/dia
  'groq',         // 100k tokens/dia + super rÃ¡pido
  'openrouter',   // FlexÃ­vel + muitos modelos
  'gemini'        // 250 req/dia (Ãºltimo recurso)
];
```

---

## ðŸ” SeguranÃ§a

### âœ… Checklist SeguranÃ§a

- [ ] Nunca comitar `.env` com chaves reais
- [ ] Sempre usar `.env.example` com valores fake no Git
- [ ] Chaves APENAS no Render (nÃ£o no cÃ³digo)
- [ ] Rotar chaves a cada 3 meses
- [ ] Monitorar uso via logs e estatÃ­sticas

### IntegraÃ§Ã£o com Render Secrets

1. GitHub â†’ Add `.env` to `.gitignore`
2. Render Dashboard â†’ Environment Variables
3. Copy chaves lÃ¡ (nunca em cÃ³digo)
4. Redeploy service

---

## ðŸ“Š ComparaÃ§Ã£o de Capacidade (Free Tier)

| Provider | Tokens/dia | Req/min | Modelos | Multimodal | Custo |
|----------|-----------|---------|---------|-----------|-------|
| **Ollama** | 1M âœ… | 60 | 7+ | Sim | $0 |
| **Groq** | 100k | 30 | 3 | NÃ£o | $0 |
| **OpenRouter** | Flex | Flex | 13+ | Sim (alguns) | $0 (free tier) |
| **Gemini** | 1M | 60 | 1 | Sim | $0 (250 req/dia) |

**ConclusÃ£o:** Ollama > Groq > OpenRouter > Gemini âœ…

---

## ðŸš€ Deployment Checklist

- [ ] Chaves configuradas no Render
- [ ] OLLAMA_BASE_URL = https://ollama.com (nÃ£o local)
- [ ] ModelSelection.ts com todos os modelos
- [ ] providers.config.ts com fallbackOrder novo
- [ ] AIStrategyRouter.ts usando arrays
- [ ] Logs configurados para monitorar rotaÃ§Ã£o
- [ ] Teste de fallback (desabilitar providers um a um)
- [ ] Cron job para resetar estatÃ­sticas diÃ¡rias

---

## ðŸ“š Arquivos Modificados

```
src/services/ai/config/
â”œâ”€â”€ ModelSelection.ts         âœ… Arrays de modelos + info
â”œâ”€â”€ providers.config.ts       âœ… Nova prioridade (Ollama 1Âº)
â””â”€â”€ AIStrategyRouter.ts       âœ… IteraÃ§Ã£o por arrays

.env.example                  âœ… Todos os providers
```

---

## âœ… Status

- âœ… **42+ modelos gratuitos** incluÃ­dos
- âœ… **Arrays com fallback** por qualidade
- âœ… **Nova prioridade** otimizada por capacidade
- âœ… **RotaÃ§Ã£o inteligente** baseada em sucesso/falha
- âœ… **Seguro** com chaves em variÃ¡veis de ambiente
- âœ… **Pronto para usar** ðŸš€

**PrÃ³ximo passo:** Configure suas chaves no Render e teste!

---

## ðŸ“ž Suporte

Precisa de ajuda?

1. Verifique as chaves no Render
2. Cheque os logs (`AIStrategyRouter.getHealth()`)
3. Teste um provider por vez
4. Verifique a documentaÃ§Ã£o especÃ­fica de cada provider

---

**Ãšltima atualizaÃ§Ã£o:** 30 de outubro de 2025
**Modelos:** 42+ (Ollama 7, Groq 3, OpenRouter 13+, Gemini 1)
**Status:** âœ… Pronto para produÃ§Ã£o
