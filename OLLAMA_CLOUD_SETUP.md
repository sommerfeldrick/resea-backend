# üåê Guia: Ollama Cloud API

## ‚úÖ Configura√ß√£o Simplificada - Ollama Cloud

Agora seu backend usa **Ollama Cloud** em vez de rodar localmente! Muito mais simples! üéâ

---

## üöÄ Passo a Passo

### 1Ô∏è‚É£ Obter API Key (GR√ÅTIS - 1M tokens/dia)

1. Acesse: **https://ollama.com/**
2. Crie uma conta (GitHub, Google ou email)
3. V√° em: **Settings ‚Üí API Keys**
4. Clique em **"Create API Key"**
5. Copie sua chave (ex: `ollama_xxxxxxxxxxxxx`)

---

### 2Ô∏è‚É£ Configurar no Render (Produ√ß√£o)

No dashboard do Render, v√° em **Environment** e adicione:

```bash
OLLAMA_API_KEY=ollama_sua_chave_aqui
OLLAMA_URL=https://api.ollama.com
EMBEDDING_MODEL=nomic-embed-text
RERANKER_MODEL=llama3.2
```

---

### 3Ô∏è‚É£ Configurar Localmente (Development)

Crie/atualize o arquivo `.env`:

```bash
# Ollama Cloud
OLLAMA_API_KEY=ollama_sua_chave_aqui
OLLAMA_URL=https://api.ollama.com
EMBEDDING_MODEL=nomic-embed-text
RERANKER_MODEL=llama3.2
```

---

### 4Ô∏è‚É£ Subir apenas os servi√ßos necess√°rios

```bash
# Agora N√ÉO precisa mais do container Ollama!
docker-compose up -d

# Inicia o backend
npm run dev
```

---

## üìä Compara√ß√£o: Local vs Cloud

| Aspecto | üñ•Ô∏è Ollama Local | ‚òÅÔ∏è Ollama Cloud |
|---------|-----------------|-----------------|
| **Setup** | Complexo (Docker, modelos) | **Simples (s√≥ API key)** ‚úÖ |
| **Custo** | Gr√°tis, mas usa seu hardware | **1M tokens/dia GR√ÅTIS** ‚úÖ |
| **Lat√™ncia** | 10-50ms (se tiver GPU) | 100-300ms |
| **Hardware** | GPU/CPU potente necess√°rio | **Nenhum** ‚úÖ |
| **Deploy** | Dif√≠cil (precisa GPU) | **F√°cil (qualquer host)** ‚úÖ |
| **Manuten√ß√£o** | Updates manuais de modelos | **Zero** ‚úÖ |
| **Privacidade** | 100% local | Dados enviados para Ollama |

---

## üéØ Modelos Dispon√≠veis

### Embeddings (Vetoriza√ß√£o)
- ‚úÖ `nomic-embed-text` (recomendado) - 768 dims, 8k context
- `mxbai-embed-large` - 1024 dims, 512 context
- `all-minilm` - 384 dims, 256 context

### Reranking (LLMs)
- ‚úÖ `llama3.2` (recomendado) - 3B params
- `phi3` - 3.8B params, mais preciso
- `gemma2` - 2B params, mais r√°pido
- `qwen2.5` - 3B params, multilingual

---

## üß™ Testar a API

### Teste de Embeddings
```bash
curl https://api.ollama.com/api/embeddings \
  -H "Authorization: Bearer ollama_sua_chave" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "nomic-embed-text",
    "prompt": "neural networks for image classification"
  }'
```

### Teste de Reranking
```bash
curl https://api.ollama.com/api/generate \
  -H "Authorization: Bearer ollama_sua_chave" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.2",
    "prompt": "Rate relevance 0-10: Query: machine learning, Document: Deep Learning Tutorial",
    "stream": false
  }'
```

---

## üì¶ O que foi removido?

### ‚ùå N√£o precisa mais:
- Container Docker do Ollama
- Download de modelos (~2.5GB)
- GPU/CPU potente
- Script `init-ollama.sh`
- Script `start-ollama.sh`

### ‚úÖ Agora s√≥ precisa:
- API Key do Ollama Cloud (gr√°tis)
- Containers: GROBID, Redis, Qdrant
- Configurar 1 vari√°vel de ambiente: `OLLAMA_API_KEY`

---

## üêõ Troubleshooting

### Erro: "401 Unauthorized"
```bash
# Verifique se a API key est√° correta
echo $OLLAMA_API_KEY

# Teste manualmente
curl https://api.ollama.com/api/tags \
  -H "Authorization: Bearer $OLLAMA_API_KEY"
```

### Erro: "Model not found"
```bash
# Modelos dispon√≠veis no Cloud:
# - nomic-embed-text
# - mxbai-embed-large
# - llama3.2
# - phi3
# - gemma2
# - qwen2.5

# Verifique se o nome est√° correto no .env
```

### Mudar para HuggingFace (alternativa)
Se preferir usar HuggingFace em vez de Ollama Cloud:
```bash
# Reverter commit
git log --oneline  # Veja os commits
git revert <commit_hash>

# Configurar HuggingFace
HUGGINGFACE_API_KEY=hf_sua_chave
```

---

## üí∞ Limites do Free Tier

| Provedor | Limite Di√°rio | Limite por Minuto | Custo Excedente |
|----------|---------------|-------------------|-----------------|
| **Ollama Cloud** | 1M tokens | Sem limite | N√£o dispon√≠vel (s√≥ free) |
| HuggingFace | 1k requests | 100 req/min | $0.0002/token |

**1M tokens = ~750k palavras = ~30k papers processados por dia**

---

## üéì Recursos

- **Ollama Cloud Docs**: https://ollama.com/docs/api
- **Pricing**: https://ollama.com/pricing (atualmente 100% gratuito)
- **Modelos**: https://ollama.com/library
- **Status**: https://status.ollama.com/

---

**Pronto! Agora seu backend usa IA na nuvem sem complica√ß√£o!** ‚òÅÔ∏èüöÄ
