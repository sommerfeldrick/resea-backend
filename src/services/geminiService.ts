import { logger } from '../config/logger.js';
import { buscaAcademicaUniversal, enrichWithPDFContent } from './academicSearchService.js';
import { generateText } from './aiProvider.js';
import { scrapeArticle, prepareForAI, calculateSavings } from './webScraper.js';
import { filterRelevantPapers } from '../utils/relevanceFilter.js';
import type {
  TaskPlan,
  MindMapData,
  AcademicSource,
  AcademicSearchFilters
} from '../types/index.js';

/**
 * Clean JSON response from AI (remove markdown code blocks and thinking tags)
 */
function cleanJsonResponse(text: string): string {
  // Remove markdown code blocks (```json ... ``` or ``` ... ```)
  // AND remove thinking tags (<think>...</think>) from models like Llama 4 Maverick
  let cleaned = text.trim();

  // Remove <think>...</think> tags (from reasoning models)
  cleaned = cleaned.replace(/<think>[\s\S]*?<\/think>/gi, '');

  // Remove ```json at the start
  if (cleaned.startsWith('```json')) {
    cleaned = cleaned.slice(7);
  } else if (cleaned.startsWith('```')) {
    cleaned = cleaned.slice(3);
  }

  // Remove ``` at the end
  if (cleaned.endsWith('```')) {
    cleaned = cleaned.slice(0, -3);
  }

  return cleaned.trim();
}

/**
 * Generate task plan from user query
 */
export async function generateTaskPlan(query: string): Promise<TaskPlan> {
  logger.info('Generating task plan', { query });

  try {
    const prompt = `Com base na consulta do usu√°rio "${query}", crie um plano detalhado de pesquisa e reda√ß√£o. A pesquisa deve ser profunda e o estilo de escrita deve ser humanizado, evitando jarg√µes excessivos para ser claro e envolvente.

Retorne APENAS um objeto JSON v√°lido (sem markdown, sem \`\`\`json) com a seguinte estrutura:
{
  "taskTitle": "t√≠tulo conciso em portugu√™s",
  "taskDescription": {
    "type": "tipo de documento (ex: 'revis√£o de literatura acad√™mica')",
    "style": "estilo de escrita (ex: 'acad√™mico formal humanizado')",
    "audience": "p√∫blico-alvo",
    "wordCount": "contagem estimada (ex: '8000-12000 palavras')"
  },
  "executionPlan": {
    "thinking": ["etapa 1 de pensamento", "etapa 2...", "..."],
    "research": ["etapa 1 de pesquisa", "etapa 2...", "..."],
    "writing": ["etapa 1 de reda√ß√£o", "etapa 2...", "..."]
  }
}`;

    const response = await generateText(prompt, {
      systemPrompt: 'Voc√™ √© um assistente de pesquisa especialista. Retorne APENAS JSON v√°lido, sem formata√ß√£o markdown.',
      temperature: 0.7,
      maxTokens: 2000
    });

    const cleanedText = cleanJsonResponse(response.text);
    const plan = JSON.parse(cleanedText);
    logger.info('Task plan generated successfully', { title: plan.taskTitle });
    return plan;
  } catch (error: any) {
    logger.error('Failed to generate task plan', { error: error.message, query });
    throw new Error('Falha ao gerar o plano de pesquisa. A API pode estar indispon√≠vel.');
  }
}

/**
 * Generate mind map from task plan
 */
export async function generateMindMap(plan: TaskPlan): Promise<MindMapData> {
  logger.info('Generating mind map', { title: plan.taskTitle });

  try {
    const prompt = `Crie uma estrutura de dados de mapa mental para o ReactFlow com base no seguinte plano de pesquisa: ${JSON.stringify(plan.executionPlan)}.

O n√≥ principal deve ser o t√≠tulo da tarefa: "${plan.taskTitle}".
Crie n√≥s para cada um dos principais temas nas fases de 'pensamento' e 'pesquisa'.
Conecte os n√≥s tem√°ticos ao n√≥ principal.

Retorne APENAS um objeto JSON v√°lido (sem markdown, sem \`\`\`json) com propriedades 'nodes' e 'edges':
- Cada n√≥ em 'nodes' deve ter 'id' (string), 'data: { label: string }', e 'position: { x: number, y: number }'.
- Posicione o n√≥ principal em { x: 250, y: 5 } e distribua os outros n√≥s ao redor dele de forma l√≥gica.
- Cada aresta em 'edges' deve ter 'id' (ex: 'e1-2'), 'source' (id do n√≥ de origem), e 'target' (id do n√≥ de destino).
O idioma deve ser portugu√™s do Brasil.`;

    const response = await generateText(prompt, {
      systemPrompt: 'Voc√™ √© um especialista em criar mapas mentais. Retorne APENAS JSON v√°lido, sem formata√ß√£o markdown.',
      temperature: 0.7,
      maxTokens: 1500
    });

    const cleanedText = cleanJsonResponse(response.text);
    const mindMapData = JSON.parse(cleanedText);
    logger.info('Mind map generated successfully');
    return mindMapData;
  } catch (error: any) {
    logger.error('Failed to generate mind map, using fallback', {
      error: error.message
    });

    // Fallback mind map
    return {
      nodes: [
        {
          id: '1',
          type: 'input',
          data: { label: plan.taskTitle },
          position: { x: 250, y: 25 }
        },
        { id: '2', data: { label: 'Pesquisa' }, position: { x: 100, y: 125 } },
        { id: '3', data: { label: 'Reda√ß√£o' }, position: { x: 400, y: 125 } }
      ],
      edges: [
        { id: 'e1-2', source: '1', target: '2', animated: true },
        { id: 'e1-3', source: '1', target: '3', animated: true }
      ]
    };
  }
}

/**
 * Perform research step with enhanced search
 */
export async function performResearchStep(
  step: string,
  originalQuery: string,
  filters: AcademicSearchFilters = {}
): Promise<{ summary: string; sources: AcademicSource[] }> {
  const combinedQuery = `${originalQuery} - ${step}`;
  logger.info('Performing research step', { step, originalQuery });

  try {
    // Search academic databases
    const academicResults = await buscaAcademicaUniversal(combinedQuery, {
      maxResults: 15,
      ...filters
    });

    if (academicResults.length === 0) {
      logger.warn('No academic results found', { step });
      return {
        summary: `Nenhum artigo acad√™mico encontrado para: "${step}". A busca continuar√° com outras fontes.`,
        sources: []
      };
    }

    // üÜï Filtrar papers por relev√¢ncia (score m√≠nimo: 0.3)
    const relevantPapers = filterRelevantPapers(academicResults, originalQuery, 0.3);

    if (relevantPapers.length === 0) {
      logger.warn('No relevant papers found after filtering', {
        step,
        originalCount: academicResults.length
      });
      return {
        summary: `Nenhum artigo relevante encontrado para: "${originalQuery}". Os ${academicResults.length} papers encontrados n√£o s√£o relacionados ao tema.`,
        sources: []
      };
    }

    logger.info(`Filtered ${academicResults.length} papers ‚Üí ${relevantPapers.length} relevant`, {
      query: originalQuery,
      filteredOut: academicResults.length - relevantPapers.length
    });

    // Optionally enrich top results with full PDF content
    const enriched = await enrichWithPDFContent(relevantPapers, 3);

    const sources: AcademicSource[] = enriched.map((res) => ({
      uri: res.url,
      title: res.title,
      authors: res.authors.join(', '),
      year: res.year,
      summary: res.abstract || '',
      sourceProvider: res.source,
      citationCount: res.citationCount,
      doi: res.doi,
      pdfUrl: res.pdfUrl
    }));

    // Use web scraping for articles with PDFs to save tokens
    const enableScraping = process.env.ENABLE_WEB_SCRAPING === 'true';
    let totalSavings = 0;

    if (enableScraping) {
      for (const source of sources.slice(0, 5)) { // Scrape top 5
        if (source.pdfUrl) {
          const scraped = await scrapeArticle(source.pdfUrl);
          if (scraped) {
            const prepared = prepareForAI(scraped);
            const savings = calculateSavings(scraped.fullText || '', prepared);
            totalSavings += savings.savingsPercent;

            // Update source with scraped data
            source.title = scraped.title;
            source.authors = scraped.authors.join(', ');
            source.summary = scraped.abstract;
            source.sections = scraped.sections;

            logger.info('Article scraped successfully', {
              title: source.title,
              tokenSavings: `${savings.savingsPercent.toFixed(0)}%`
            });
          }
        }
      }

      if (totalSavings > 0) {
        logger.info('Total token savings from scraping', {
          averageSavings: `${(totalSavings / Math.min(5, sources.length)).toFixed(0)}%`
        });
      }
    }

    // Build context from abstracts and sections
    const contexto = sources
      .map((s, idx) => {
        let context = `[${idx + 1}] ${s.title}`;
        if (s.authors) context += `\nAutores: ${s.authors}`;
        if (s.year) context += ` (${s.year})`;
        if (s.citationCount) context += ` | Cita√ß√µes: ${s.citationCount}`;
        if (s.summary) context += `\nResumo: ${s.summary}`;

        // Add section snippets if available
        if (s.sections?.abstract) {
          context += `\nAbstract: ${s.sections.abstract.substring(0, 500)}...`;
        }
        if (s.sections?.conclusion) {
          context += `\nConclus√£o: ${s.sections.conclusion.substring(0, 300)}...`;
        }

        return context;
      })
      .join('\n\n---\n\n');

    const prompt = `Com base nos artigos acad√™micos abaixo, forne√ßa um resumo anal√≠tico e detalhado em portugu√™s do Brasil sobre o t√≥pico de pesquisa: "${step}" (contexto geral: "${originalQuery}").

O resumo deve:
1. Sintetizar os principais achados e contribui√ß√µes dos artigos
2. Identificar consensos e diverg√™ncias entre os autores
3. Destacar metodologias relevantes
4. Apontar lacunas ou oportunidades de pesquisa futura
5. Ser escrito em linguagem acad√™mica mas acess√≠vel

Artigos:
${contexto}`;

    // Use multi-AI provider instead of direct Gemini call
    const response = await generateText(prompt, {
      systemPrompt: 'Voc√™ √© um assistente de pesquisa acad√™mica especializado em an√°lise cr√≠tica de literatura cient√≠fica.',
      temperature: 0.7,
      maxTokens: 2000
    });

    logger.info('Research step completed', {
      step,
      sourcesFound: sources.length,
      aiProvider: response.provider
    });

    return {
      summary: response.text,
      sources
    };
  } catch (error: any) {
    logger.error('Research step failed', {
      step,
      error: error.message
    });

    return {
      summary: `Falha ao pesquisar: "${step}". A API pode estar temporariamente indispon√≠vel.`,
      sources: []
    };
  }
}

/**
 * Generate document outline
 */
export async function generateOutline(
  plan: TaskPlan,
  researchResults: Array<{ query: string; summary: string }>
): Promise<string> {
  logger.info('Generating outline');

  try {
    const researchContext = researchResults
      .map((r) => `T√≥pico: ${r.query}\nResumo: ${r.summary}`)
      .join('\n\n');

    const prompt = `
    Com base no plano de tarefa e nos resultados da pesquisa abaixo, crie um esbo√ßo (outline) detalhado em formato Markdown para o documento final.
    O esbo√ßo deve organizar os pontos principais, argumentos e onde as cita√ß√µes podem ser usadas.
    O idioma de sa√≠da deve ser o portugu√™s do Brasil.

    PLANO DA TAREFA:
    - T√≠tulo: ${plan.taskTitle}
    - Plano de Reda√ß√£o: ${plan.executionPlan.writing.join(', ')}

    RESULTADOS DA PESQUISA:
    ${researchContext}

    Crie o esbo√ßo agora em formato Markdown com se√ß√µes numeradas.
    `;

    const response = await generateText(prompt, {
      systemPrompt: 'Voc√™ √© um especialista em estrutura√ß√£o de documentos acad√™micos.',
      temperature: 0.5,
      maxTokens: 1500
    });

    logger.info('Outline generated successfully', { provider: response.provider });
    return response.text;
  } catch (error: any) {
    logger.error('Failed to generate outline', { error: error.message });
    return '## Erro ao Gerar o Esbo√ßo\n\nN√£o foi poss√≠vel criar o esbo√ßo do documento.';
  }
}

/**
 * Generate final content with streaming
 */
export async function* generateContentStream(
  plan: TaskPlan,
  researchResults: Array<{
    query: string;
    summary: string;
    sources: AcademicSource[];
  }>
): AsyncGenerator<string> {
  logger.info('Starting content generation stream');

  try {
    // Collect all unique sources
    const uniqueSources = [
      ...new Map(
        researchResults.flatMap((r) => r.sources).map((item) => [item.uri, item])
      ).values()
    ];

    if (uniqueSources.length === 0) {
      yield '## Documento Final\n\nN√£o foram encontradas fontes acad√™micas suficientes.';
      return;
    }

    // Build research context with full metadata
    const researchContext =
      `A pesquisa resultou nas seguintes fontes. Use-as para embasar o texto.\n\n` +
      uniqueSources
        .map((source, index) => {
          const authors = source.authors || 'Autor Desconhecido';
          const year = source.year || new Date().getFullYear();

          let citationText = 'AUTOR, ANO';
          try {
            const authorList = authors.split(',');
            const firstAuthorSurname = (
              authorList[0]?.trim().split(' ').pop() || ''
            ).toUpperCase();

            if (authorList.length > 3) {
              citationText = `${firstAuthorSurname} et al., ${year}`;
            } else if (authorList.length > 1) {
              const lastAuthorSurname = (
                authorList[authorList.length - 1]?.trim().split(' ').pop() || ''
              ).toUpperCase();
              citationText = `${firstAuthorSurname}; ${lastAuthorSurname}, ${year}`;
            } else {
              citationText = `${firstAuthorSurname}, ${year}`;
            }
          } catch (e) {
            citationText = `FONTE ${index + 1}, ${year}`;
          }

          let sourceInfo = `FONTE_${index + 1}:
- Cita√ß√£o no texto (formato ABNT): (${citationText})
- Autores: ${authors}
- Ano: ${year}
- T√≠tulo: ${source.title}
- URL: ${source.uri}`;

          if (source.citationCount) {
            sourceInfo += `\n- Cita√ß√µes: ${source.citationCount}`;
          }

          if (source.doi) {
            sourceInfo += `\n- DOI: ${source.doi}`;
          }

          // Add key sections if available
          if (source.sections?.abstract) {
            sourceInfo += `\n- Abstract: ${source.sections.abstract.substring(0, 300)}...`;
          }

          if (source.sections?.conclusion) {
            sourceInfo += `\n- Conclus√£o: ${source.sections.conclusion.substring(0, 300)}...`;
          }

          return sourceInfo;
        })
        .join('\n\n');

    const prompt = `
    Voc√™ √© um escritor acad√™mico especialista, perito em formata√ß√£o de trabalhos cient√≠ficos segundo as normas da ABNT.

    PLANO DA TAREFA:
    - T√≠tulo: ${plan.taskTitle}
    - Descri√ß√£o: ${JSON.stringify(plan.taskDescription)}

    FONTES DE PESQUISA (${uniqueSources.length} papers cient√≠ficos):
    ${researchContext}

    ‚ö†Ô∏è ATEN√á√ÉO: Voc√™ DEVE citar TODAS as fontes acima ao longo do texto usando o formato [CITE:FONTE_X] (AUTOR, ANO).

    Escreva um documento acad√™mico completo em portugu√™s do Brasil, seguindo RIGOROSAMENTE:

    1. **Estrutura ABNT Completa**:
       - T√≠tulo principal (# T√≠tulo)
       - Resumo executivo (## Resumo)
       - Introdu√ß√£o (## 1. Introdu√ß√£o)
       - Desenvolvimento com cap√≠tulos numerados (## 2. ..., ## 3. ...)
       - Conclus√£o (## ${uniqueSources.length + 2}. Conclus√£o)
       - Refer√™ncias Bibliogr√°ficas (## Refer√™ncias)

    2. **Cita√ß√µes OBRIGAT√ìRIAS em CADA par√°grafo**:
       Formato: "...afirma√ß√£o cient√≠fica [CITE:FONTE_1] (SILVA et al., 2022)."

       EXEMPLO CORRETO:
       "A an√°lise de elementos finitos (AEF) tem sido amplamente utilizada na biomec√¢nica oral [CITE:FONTE_1] (YANG et al., 2020). Estudos recentes demonstram sua efic√°cia na simula√ß√£o de for√ßas oclusais [CITE:FONTE_2] (FERREIRA; SANTOS, 2021)."

       ‚ùå INCORRETO (sem cita√ß√µes): "A an√°lise de elementos finitos √© importante na odontologia."
       ‚úÖ CORRETO (com cita√ß√µes): "A an√°lise de elementos finitos √© importante na odontologia [CITE:FONTE_1] (YANG et al., 2020)."

    3. **Linguagem Acad√™mica**:
       - Tom formal e impessoal
       - Verbos no presente do indicativo ou pret√©rito perfeito
       - Evite opini√£o pessoal, use "observa-se que", "verificou-se que"

    4. **Formato Markdown**:
       - T√≠tulos com ## (h2) e ### (h3)
       - Par√°grafos com quebras de linha duplas
       - Negrito em termos t√©cnicos importantes

    5. **Se√ß√£o de Refer√™ncias COMPLETA**:
       Liste TODAS as ${uniqueSources.length} fontes em formato ABNT:

       SOBRENOME, Prenome. **T√≠tulo do artigo**. _Nome da revista_, v. X, n. Y, p. Z-W, ano. Dispon√≠vel em: <URL>. Acesso em: ${new Date().toLocaleDateString('pt-BR')}.

    6. **Tamanho M√≠nimo**: ${plan.taskDescription.wordCount || '3000-5000 palavras'}

    COMECE AGORA COM O DOCUMENTO COMPLETO. N√ÉO ESQUE√áA DE CITAR CADA FONTE!
    `;

    // Use multi-AI provider
    const result = await generateText(prompt, {
      systemPrompt: 'Voc√™ √© um escritor acad√™mico especialista, perito em formata√ß√£o de trabalhos cient√≠ficos segundo as normas da ABNT.',
      temperature: 0.7
    });

    yield result.text;

    logger.info('Content generation stream completed');
  } catch (error: any) {
    logger.error('Content generation stream failed', { error: error.message });
    yield '\n\n**Ocorreu um erro ao gerar o documento final.**';
  }
}
